{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение обученных моделей и выбор основы чат-бота\n",
    "\n",
    "На предыдущем этапе мною была обучена модель flan-t5-base\n",
    "\n",
    "\n",
    "На этапе обучения на валидационной выборке рассчитывалась метрика rouge и bertscore для оценки похожести сгенерированного текста с ответом из сценария\n",
    "\n",
    "Хотя данная метрика используется для оценки качества суммаризации, было интересно посмотреть как она сработает в случае диалоговой системы. Также она позволяет сравнивать модели между собой вовремя обучения. Я решила дополнить эту оценку косинусоной близостью с эталонным ответом (воспользуюсь моделью би-энкодера, обученного на предыдущей задаче) и насколько сгенерированный ответ подходит для вопроса и котекста (воспользуюсь моделью reranker, обученного на предыдущей задаче)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import encode, cosine_sim\n",
    "import warnings\n",
    "import wandb\n",
    "import json\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовим тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There’s no point, I just think it’s a good id...</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think this is the place.</td>\n",
       "      <td>If you have to ask, maybe you shouldn’t be here.</td>\n",
       "      <td>Hang on.  One across is Aegean, eight down is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think this is the place.</td>\n",
       "      <td>If you have to ask, maybe you shouldn’t be here.</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this is the place.</td>\n",
       "      <td>If you have to ask, maybe you shouldn’t be here.</td>\n",
       "      <td>Can I help you? Yes. Um, is this the High IQ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think this is the place.</td>\n",
       "      <td>If you have to ask, maybe you shouldn’t be here.</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0   There’s no point, I just think it’s a good id...   \n",
       "1                         I think this is the place.   \n",
       "2                         I think this is the place.   \n",
       "3                         I think this is the place.   \n",
       "4                         I think this is the place.   \n",
       "\n",
       "                                            question  \\\n",
       "0                         Agreed, what’s your point?   \n",
       "1   If you have to ask, maybe you shouldn’t be here.   \n",
       "2   If you have to ask, maybe you shouldn’t be here.   \n",
       "3   If you have to ask, maybe you shouldn’t be here.   \n",
       "4   If you have to ask, maybe you shouldn’t be here.   \n",
       "\n",
       "                                             context  \n",
       "0                                                     \n",
       "1   Hang on.  One across is Aegean, eight down is...  \n",
       "2   One across is Aegean, eight down is Nabakov, ...  \n",
       "3   Can I help you? Yes. Um, is this the High IQ ...  \n",
       "4           Yes. Um, is this the High IQ sperm bank?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data/scripts_reworked.pkl\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.sample(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подходы к генерации текста\n",
    "\n",
    "Первым шагом необходимо сгенерировать ответы \n",
    "Для генерации воспользуемся стратегией семплирования и выберем в качестве сравниваемых параметров top_p + temperature. \n",
    "\n",
    "Создадим функцию для генерации, которая будет принимать модель, ее токенайзер, знак зодиака для генерация и оба параметра. Эту функцию будем использовать в другой функции при оценке генерируемых текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model,model_name, tokenizer, question, context, top_p, temperature):\n",
    "    combined = \"context: \" + context + \"</s>\" + \"question: \" + question\n",
    "    input_ids = tokenizer.encode(combined, return_tensors=\"pt\")\n",
    "    sample_output = model.generate(\n",
    "        input_ids.to(device),\n",
    "        do_sample=True,\n",
    "        max_length=1000,\n",
    "        top_p=top_p,\n",
    "        temperature=temperature,\n",
    "        repetition_penalty=2.0,\n",
    "        top_k=50,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    if model_name == \"T5\":\n",
    "        return tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
    "    else:\n",
    "        out = tokenizer.decode(sample_output[0][1:], skip_special_tokens=True)\n",
    "        if \"</s>\" in out:\n",
    "            out = out[: out.find(\"</s>\")].strip()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подходы к оценке текста\n",
    "Разные модели и стратегии генерации будем сравнивать и оценивать на сходство с эталонным ответом, который есть в сценарии на основе небольшой случайной выборки из данных:\n",
    "\n",
    "1. Сходство с оригиналом по косинусной близости. \n",
    "2. Время генерации ответа - бот будет работать на cpu, поэтому сравнительное время интересно посомотреть (относительные параметры не показательны, так как бот будет разворачиваться на разных машинах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ranking_model = SentenceTransformer(\"Shakhovak/chatbot_sentence-transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatya_shakhova\u001b[0m (\u001b[33mshakhova\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Kate\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    json_config = json.load(f)\n",
    "TOKEN = json_config[\"token\"]\n",
    "wandb.login(key=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_gen(test_df, model, model_name, tokenizer, top_p, temperature):\n",
    "    print_top_p = str(int(top_p*10))\n",
    "    print_temperature = str(int(temperature * 10))\n",
    "\n",
    "    generated_results = pd.DataFrame()\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"generative_models_chat\",\n",
    "        name=f\"{model_name}_top_p={print_top_p}_temp={print_temperature}\",\n",
    "    )\n",
    "    wandb.define_metric(\"gen_time\", summary=\"mean\")\n",
    "    wandb.define_metric(\"cosine_scores\", summary=\"mean\")\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "\n",
    "        start = time.time()\n",
    "        gen_text = generate_response(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                question=row['question'],\n",
    "                context=row['context'], \n",
    "                tokenizer=tokenizer,           \n",
    "                top_p=top_p,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "        logging.info(f\"Generation for model {model_name} finished!\")\n",
    "\n",
    "        end = time.time()\n",
    "        gen_time = round(end - start, 4)\n",
    "\n",
    "        # check context format!!!\n",
    "        answer_true_encoding = encode(\n",
    "            texts=row['answer'],\n",
    "            model=ranking_model,\n",
    "            contexts=row['context'],\n",
    "        )\n",
    "\n",
    "        answer_generated_encoding = encode(\n",
    "            texts=gen_text,\n",
    "            model=ranking_model,\n",
    "            contexts=row[\"context\"],\n",
    "        )\n",
    "\n",
    "        cosine_scores = cosine_sim(\n",
    "            answer_true_encoding,\n",
    "            answer_generated_encoding,\n",
    "        )\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"gen_time\": gen_time,\n",
    "                \"cosine_scores\": cosine_scores,\n",
    "            }\n",
    "            )\n",
    "\n",
    "        new_row = {\n",
    "            f\"{model_name}_gen_answer\": gen_text,\n",
    "            \"answer_true\": row['answer'],\n",
    "            \"question\":row['question'],\n",
    "            \"context\": row['context'],\n",
    "            f\"{model_name}_gen_time\": gen_time,\n",
    "            f\"{model_name}_cos_sim_biencoder\": cosine_scores,\n",
    "        }\n",
    "\n",
    "        generated_results = pd.concat([generated_results, pd.DataFrame([new_row])])\n",
    "\n",
    "    data_to_log = wandb.Table(dataframe=generated_results)\n",
    "    run.log({f\"{model_name}_top_p={print_top_p}_temp={print_temperature}\": data_to_log})\n",
    "\n",
    "    logging.info(f\"Artifacts for model {model_name} loaded to wandb!\")\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flan-t5-base v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_flan = AutoTokenizer.from_pretrained(\"Shakhovak/flan-t5-base-sheldon-chat-v2\")\n",
    "model_flan = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"Shakhovak/flan-t5-base-sheldon-chat-v2\"\n",
    ")\n",
    "model_flan.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_combinations = [(0.2,0.1),(0.7, 0.8),(0.5,0.5), (1, 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Kate\\chat_bot_katya_HW2\\wandb\\run-20240307_165228-6bt06cn9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shakhova/generative_models_chat/runs/6bt06cn9' target=\"_blank\">flan_top_p=1_temp=2</a></strong> to <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shakhova/generative_models_chat/runs/6bt06cn9' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/6bt06cn9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cosine_scores</td><td>▅▅███▇▆▆▆▄▂▅▄▅▆▇▆▇▂▃█▇█▁█▆██▄▄</td></tr><tr><td>gen_time</td><td>█▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flan_top_p=1_temp=2</strong> at: <a href='https://wandb.ai/shakhova/generative_models_chat/runs/6bt06cn9' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/6bt06cn9</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240307_165228-6bt06cn9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Kate\\chat_bot_katya_HW2\\wandb\\run-20240307_165241-xvv5dpl8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shakhova/generative_models_chat/runs/xvv5dpl8' target=\"_blank\">flan_top_p=8_temp=7</a></strong> to <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shakhova/generative_models_chat/runs/xvv5dpl8' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/xvv5dpl8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cosine_scores</td><td>▅▅███▇▅▆▇▅▂▆▄▄▆▇▂▇▂▃▆▆█▁█▁▇█▄▆</td></tr><tr><td>gen_time</td><td>▇▁▃▃▂▅▅▁▁█▂▃▃▄▂▂▄▃▃▅▆▁▆▃▄▂▄▅▃▁</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flan_top_p=8_temp=7</strong> at: <a href='https://wandb.ai/shakhova/generative_models_chat/runs/xvv5dpl8' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/xvv5dpl8</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240307_165241-xvv5dpl8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Kate\\chat_bot_katya_HW2\\wandb\\run-20240307_165258-sl2hnlpt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shakhova/generative_models_chat/runs/sl2hnlpt' target=\"_blank\">flan_top_p=5_temp=5</a></strong> to <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shakhova/generative_models_chat/runs/sl2hnlpt' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/sl2hnlpt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cosine_scores</td><td>▅▄███▁▅▆▆▃▁▅▃▄▁▇▁▇▁▂█▇███▆█▇▃▃</td></tr><tr><td>gen_time</td><td>▂▁▅▅▃▂▅▂▃▅▅▃▅▅▅▃▆▅▂▅█▁▄▂█▆▆▅▆▅</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flan_top_p=5_temp=5</strong> at: <a href='https://wandb.ai/shakhova/generative_models_chat/runs/sl2hnlpt' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/sl2hnlpt</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240307_165258-sl2hnlpt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Kate\\chat_bot_katya_HW2\\wandb\\run-20240307_165309-t72qkfsb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shakhova/generative_models_chat/runs/t72qkfsb' target=\"_blank\">flan_top_p=9_temp=10</a></strong> to <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shakhova/generative_models_chat' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shakhova/generative_models_chat/runs/t72qkfsb' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/t72qkfsb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cosine_scores</td><td>▆▅▄▅▇▁▆▆▆▄▁▄▆▆▆▄▆▇▁▁█▇▆▇█▄█▂▆▃</td></tr><tr><td>gen_time</td><td>▂▁▃▃▅▄▂▁▄▆▅▁▃▆▁▂▃▄▃█▂▁▂▄▃▃▂▃▂▁</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flan_top_p=9_temp=10</strong> at: <a href='https://wandb.ai/shakhova/generative_models_chat/runs/t72qkfsb' target=\"_blank\">https://wandb.ai/shakhova/generative_models_chat/runs/t72qkfsb</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240307_165309-t72qkfsb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in parameters_combinations:\n",
    "    review_gen(test_df=test, \n",
    "                model=model_flan,\n",
    "                model_name='flan',\n",
    "                tokenizer=tokenizer_flan,\n",
    "                top_p=i[1], temperature=i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
